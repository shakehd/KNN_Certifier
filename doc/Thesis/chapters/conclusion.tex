%!TEX root = ../dissertation.tex

\chapter{Conclusion and Future Works}
\label{chp:conclusion-future-works}

The purpose of this work was to certify the stability and robustness of the \acs{$k$-NN} algorithm against adversarial attacks, specifically to determine whether the prediction of the \acs{$k$-NN} classifier remains consistent when the features of the input sample are slightly perturbed. To this end we first modified the way the standard \acs{$k$-NN} algorithm finds the $k$ closest samples leveraging the relation of \textit{relative proximity} of training samples to the input $\vinput$ without explicitly computing Euclidean distances. We then developed a novel algorithm that, given an adversarial attack modeled as small region of space around the input $\vinput$, computes the set of labels that points within the adversarial region can be classified with by \acs{$k$-NN}. If this set contains only a single label then we can guarantee with absolute certainty the stability of \acs{$k$-NN} for the input $\vinput$ with respect to the adversarial region. Additionally, if this single label coincides with the ground truth of $\vinput$, we can also conclude that the \acs{$k$-NN} classifier is also robust for $\vinput$ within the defined adversarial region. We experimented with our algorithm on different standard datasets for \acs{$k$-NN} evaluation, showing that our approach generally scales well and is effective, and that \acs{$k$-NN} is in general robust for numerical perturbations of up to $\pm 3\%$. However, further improvements to this algorithm are possible, particularly aiming to reduce the certification runtime. For example, leveraging high-order Voronoi diagram properties to better approximate the upper bound on path length and terminate path exploration earlier is worth exploring. As future challenge would be interesting to adapt the algorithm to distance metrics other than Euclidean distance, like the Manhattan distance.

